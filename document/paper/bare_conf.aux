\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mcfarland1993intelligent}
\citation{janglova2005neural}
\citation{conradt2000}
\newcplabel{^_1}{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{krichmar2011}
\citation{truenorth2014}
\citation{furber2007neural,furber2014spinnaker}
\citation{eliasmith2004neural}
\citation{closedloop2015}
\citation{kim2007encoding}
\citation{verschure2012distributed}
\citation{suttonbarto1998}
\citation{boureau2010}
\citation{conradt2009embedded}
\citation{muller2011miniature}
\citation{denk2013}
\citation{furber2007neural,furber2014spinnaker}
\citation{bekolay_nengo2014}
\citation{mundy2015}
\@writefile{toc}{\contentsline {section}{\numberline {2}Infrastructure}{3}{section.2}}
\newlabel{infrastructure}{{2}{3}{Infrastructure}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.1}}Embedded Dynamic Vision Sensor: eDVS}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.2}}Small Mobile Robot: PushBot}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.3}}Neuromorphic Computing System: SpiNNaker}{3}{subsection.2.3}}
\citation{eliasmith2004neural}
\citation{eliasmith_largescale_2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {{2.4}}Nengo and the Neural Engineering Framework}{4}{subsection.2.4}}
\citation{muller2011miniature}
\citation{bekolay_nengo2014}
\citation{mundy2015}
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{5}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{3.1}}Initial Reflexive Control}{5}{subsection.3.1}}
\citation{kim2007encoding}
\@writefile{toc}{\contentsline {subsection}{\numberline {{3.2}}Serendipitous Offline Learning}{8}{subsection.3.2}}
\newlabel{learning}{{{3.2}}{8}{Serendipitous Offline Learning}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{9}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.1}}Simulated scenario}{9}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.2}}Initial behavior}{9}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.3}}Learning Example 1: Basic Responses}{10}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {{4.4}}Learning Example 2: Sensory Conditions}{10}{subsection.4.4}}
\newlabel{learningConditions}{{{4.4}}{10}{Learning Example 2: Sensory Conditions}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{10}{section.5}}
\citation{eliasmith2004neural}
\citation{conradt2014trainable}
\citation{boureau2010}
\citation{kolbeck2013fear}
\bibstyle{frontiersinSCNS_ENG_HUMS}
\bibdata{refs}
\bibcite{bekolay_nengo2014}{{1}{2014}{{Bekolay et~al.}}{{Bekolay, Bergstra, Hunsberger, DeWolf, Stewart, Rasmussen et~al.}}}
\bibcite{boureau2010}{{2}{2010}{{Boureau and Dayan}}{{}}}
\bibcite{conradt2009embedded}{{3}{2009}{{Conradt et~al.}}{{Conradt, Berner, Cook, and Delbruck}}}
\bibcite{conradt2014trainable}{{4}{2014}{{Conradt et~al.}}{{Conradt, Galluppi, and Stewart}}}
\bibcite{conradt2000}{{5}{2000}{{Conradt et~al.}}{{Conradt, Tevatia, Vijayakumar, and Schaal}}}
\bibcite{denk2013}{{6}{2013}{{Denk et~al.}}{{Denk, Llobet-Blandino, Galluppi, Plana, Furber, and Conradt}}}
\bibcite{eliasmith2004neural}{{7}{2004}{{Eliasmith and Anderson}}{{}}}
\bibcite{eliasmith_largescale_2012}{{8}{2012}{{Eliasmith et~al.}}{{Eliasmith, Stewart, Choo, Bekolay, DeWolf, Tang et~al.}}}
\bibcite{furber2014spinnaker}{{9}{2014}{{Furber et~al.}}{{Furber, Galluppi, Temple, Plana et~al.}}}
\bibcite{furber2007neural}{{10}{2007}{{Furber and Temple}}{{}}}
\bibcite{janglova2005neural}{{11}{2005}{{Janglov{\'a}}}{{}}}
\bibcite{kim2007encoding}{{12}{2007}{{Kim et~al.}}{{Kim, Huh, Lee, Baeg, Lee, and Jung}}}
\bibcite{kolbeck2013fear}{{13}{2013}{{Kolbeck et~al.}}{{Kolbeck, Bekolay, and Eliasmith}}}
\bibcite{krichmar2011}{{14}{2011}{{Krichmar and Wagatsuma}}{{}}}
\bibcite{mcfarland1993intelligent}{{15}{1993}{{McFarland and B{\"o}sser}}{{}}}
\bibcite{truenorth2014}{{16}{2014}{{Merolla et~al.}}{{Merolla, Arthur, Alvarez-Icaza, Cassidy, Sawada, Akopyan et~al.}}}
\bibcite{muller2011miniature}{{17}{2011}{{M{\"u}ller and Conradt}}{{}}}
\bibcite{mundy2015}{{18}{2015}{{Mundy et~al.}}{{Mundy, Knight, Stewart, and Furber}}}
\bibcite{closedloop2015}{{19}{2015}{{Stewart et~al.}}{{Stewart, DeWolf, Kleinhans, and Eliasmith}}}
\bibcite{suttonbarto1998}{{20}{1998}{{Sutton and Barto}}{{}}}
\bibcite{verschure2012distributed}{{21}{2012}{{Verschure}}{{}}}
\global\@namedef{@lastpage@}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The PushBot robot with LEDs on the front and back (1), a control board (2) with an eDVS silicon retina (3) and NXP LPC4337 microcontroller (4), and a laser pointer (5). The robot communicates through a wireless module on the back (not visible). The top-left insert shows the laser pointer in red.}}{14}{figure.1}}
\newlabel{fig_sim}{{1}{14}{The PushBot robot with LEDs on the front and back (1), a control board (2) with an eDVS silicon retina (3) and NXP LPC4337 microcontroller (4), and a laser pointer (5). The robot communicates through a wireless module on the back (not visible). The top-left insert shows the laser pointer in red}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Voltage $V$, spiking activity and output of a single LIF neuron, given a constant input $I$. SpiNNaker uses a simulation time step of $dt=0.001$.}}{14}{figure.2}}
\newlabel{Neuron}{{2}{14}{Voltage $V$, spiking activity and output of a single LIF neuron, given a constant input $I$. SpiNNaker uses a simulation time step of $dt=0.001$}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A network implementing basic reactive control. Square boxes are the values being represented by the neurons (circles). Random connectivity ensures the neurons form a distributed representation of the vector values that are their input. The optimised output connections are solved for using least-squares minimization to approximate the functions listed in the text. Learned connections are added afterwards, as discussed in section \ref  {learning}.}}{14}{figure.3}}
\newlabel{Flow}{{3}{14}{A network implementing basic reactive control. Square boxes are the values being represented by the neurons (circles). Random connectivity ensures the neurons form a distributed representation of the vector values that are their input. The optimised output connections are solved for using least-squares minimization to approximate the functions listed in the text. Learned connections are added afterwards, as discussed in section \ref {learning}}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Neural approximation with the NEF. When connections between neural groups are optimized to approximate a function, the result is a smooth version of that function. As the number of neurons is increased, this neural approximation will approach the ideal function.}}{15}{figure.4}}
\newlabel{NEF}{{4}{15}{Neural approximation with the NEF. When connections between neural groups are optimized to approximate a function, the result is a smooth version of that function. As the number of neurons is increased, this neural approximation will approach the ideal function}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The T-Maze environment, top-down view. The robot starts at the bottom of the T shape. A mirror is sometimes placed at the intersection (see \ref  {learningConditions}).}}{15}{figure.5}}
\newlabel{Tmaze}{{5}{15}{The T-Maze environment, top-down view. The robot starts at the bottom of the T shape. A mirror is sometimes placed at the intersection (see \ref {learningConditions})}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The learning algorithm applied to a simple synthetic data set. Sensor data is a ramp (top), and a single positive example is given where the action is performed in the middle of the ramp (bottom ``ideal'' line). Resulting performance after one training example is 0.997, measured as the normalized dot product between the ideal and the trained result.}}{15}{figure.6}}
\newlabel{SimBasic}{{6}{15}{The learning algorithm applied to a simple synthetic data set. Sensor data is a ramp (top), and a single positive example is given where the action is performed in the middle of the ramp (bottom ``ideal'' line). Resulting performance after one training example is 0.997, measured as the normalized dot product between the ideal and the trained result}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The learning algorithm applied to a more complex data set. Sensor data (top) is six-dimensional random gaussian white noise with an added random signal when the action should be performed (see text for details). After a single training example, the result is somewhat correct, but it also performs the action many times when it should not (middle). After 50 training examples, the network is more reliable at performing the action only when it should.}}{16}{figure.7}}
\newlabel{SimAdvanced}{{7}{16}{The learning algorithm applied to a more complex data set. Sensor data (top) is six-dimensional random gaussian white noise with an added random signal when the action should be performed (see text for details). After a single training example, the result is somewhat correct, but it also performs the action many times when it should not (middle). After 50 training examples, the network is more reliable at performing the action only when it should}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Model performance as the signal strength $|\alpha |$ and the number of positive training examples is varied. The synthetic data set used here is the same as in Figure\nobreakspace  {}\ref  {SimAdvanced}. Performance is the similarity between the network's output and the desired ideal output, as measured with the normalized dot product.}}{16}{figure.8}}
\newlabel{SimData}{{8}{16}{Model performance as the signal strength $|\alpha |$ and the number of positive training examples is varied. The synthetic data set used here is the same as in \figurename ~\ref {SimAdvanced}. Performance is the similarity between the network's output and the desired ideal output, as measured with the normalized dot product}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Behavior of reactive control model over multiple runs. The speed (top graph) is high at the beginning, then slows as it turns either left or right (bottom graph). While on any individual run the robot tends to turn consistently either left or right, the overall average is zero turning (black area in bottom graph; area is 95\% bootstrap confidence interval).}}{16}{figure.9}}
\newlabel{React}{{9}{16}{Behavior of reactive control model over multiple runs. The speed (top graph) is high at the beginning, then slows as it turns either left or right (bottom graph). While on any individual run the robot tends to turn consistently either left or right, the overall average is zero turning (black area in bottom graph; area is 95\% bootstrap confidence interval)}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Behavior after learning to turn left. By adding connections optimized to approximate situations where the robot behaved appropriately, we implicitly program the robot to map its sensory states to its actions as desired.}}{17}{figure.10}}
\newlabel{Left}{{10}{17}{Behavior after learning to turn left. By adding connections optimized to approximate situations where the robot behaved appropriately, we implicitly program the robot to map its sensory states to its actions as desired}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Behavior after learning to turn right if there is a mirror, and otherwise turn left. The robot successfully identifies the correct situation and turns appropriately. Robot speed is not shown, but is similar to that depicted at the top of Figure\nobreakspace  {}\ref  {React}}}{17}{figure.11}}
\newlabel{Right}{{11}{17}{Behavior after learning to turn right if there is a mirror, and otherwise turn left. The robot successfully identifies the correct situation and turns appropriately. Robot speed is not shown, but is similar to that depicted at the top of \figurename ~\ref {React}}{figure.11}{}}
